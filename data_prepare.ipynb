{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62e9808-1cf1-4e2e-b4ca-e3d276167a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import AutoProcessor, EncodecModel\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adde234b-1cfa-40d9-8ae2-b2fb7a386dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Function to download an audio file from a URL\n",
    "def download_audio(url, save_path):\n",
    "    url = \"https:\" + url\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    return save_path\n",
    "\n",
    "# Function to process and encode a single WAV file\n",
    "def encode_wav_file(file_path):\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "    # Resample to 24kHz if necessary\n",
    "    if sample_rate != 24000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=24000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    waveform = waveform.squeeze().numpy()\n",
    "\n",
    "    # Ensure that the audio has a single channel\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform[0]\n",
    "    \n",
    "    # Encode the waveform\n",
    "    inputs = processor(waveform, sampling_rate=24000, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        audio_codes = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"], 24.0)\n",
    "    return audio_codes[0].squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "715b15fb-1ddd-4233-a740-c3162991d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in c:\\users\\ripple\\anaconda3\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\ripple\\anaconda3\\lib\\site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ripple\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "C:\\Users\\Ripple\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "  0%|                                                                                         | 0/5339 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio codes torch.Size([1, 1, 2, 1541])\n",
      "shape torch.Size([1, 1, 2, 1541])\n",
      "decoded (493120,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 1/5339 [00:23<34:27:13, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio codes torch.Size([1, 1, 2, 3731])\n",
      "shape torch.Size([1, 1, 2, 3731])\n",
      "decoded (1193920,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 1/5339 [01:14<109:46:00, 74.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Encode the audio file\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     audio_codes \u001b[38;5;241m=\u001b[39m encode_wav_file(file_path)\n\u001b[1;32m---> 89\u001b[0m     decode_and_play_audio(audio_codes)\n\u001b[0;32m     90\u001b[0m     final_dataset\u001b[38;5;241m.\u001b[39mappend((common_name, audio_codes))\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[22], line 60\u001b[0m, in \u001b[0;36mdecode_and_play_audio\u001b[1;34m(audio_codes)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Play the decoded audio\u001b[39;00m\n\u001b[0;32m     59\u001b[0m sd\u001b[38;5;241m.\u001b[39mplay(audio_np, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24000\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m sd\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _last_callback\u001b[38;5;241m.\u001b[39mwait(ignore_errors)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, EncodecModel\n",
    "!pip install sounddevice\n",
    "import sounddevice as sd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to download an audio file from a URL\n",
    "def download_audio(url, save_path):\n",
    "    url = \"https:\" + url\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    return save_path\n",
    "\n",
    "# Function to process and encode a single WAV file\n",
    "def encode_wav_file(file_path):\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "    # Resample to 24kHz if necessary\n",
    "    if sample_rate != 24000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=24000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    waveform = waveform.squeeze().numpy()\n",
    "\n",
    "    # Ensure that the audio has a single channel\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform[0]\n",
    "    \n",
    "    # Encode the waveform\n",
    "    inputs = processor(waveform, sampling_rate=24000, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        audio_codes = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"], 1.5)\n",
    "        print('audio codes', audio_codes[0].shape)\n",
    "        \n",
    "    return audio_codes[0].squeeze().cpu().numpy()\n",
    "\n",
    "# Function to decode audio codes and play the audio\n",
    "def decode_and_play_audio(audio_codes):\n",
    "    audio_codes_tensor = torch.from_numpy(audio_codes).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    print('shape', audio_codes_tensor.shape)\n",
    "    \n",
    "    # Decode the audio codes\n",
    "    with torch.no_grad():\n",
    "        decoded_waveform = model.decode(audio_codes_tensor, [None])[0].cpu().numpy()\n",
    "\n",
    "    audio_np = decoded_waveform.squeeze()\n",
    "    print('decoded', audio_np.shape)\n",
    "    # Play the decoded audio\n",
    "    sd.play(audio_np, samplerate=24000)\n",
    "    sd.wait()\n",
    "\n",
    "# Load the Encodec model and processor\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")\n",
    "model = EncodecModel.from_pretrained(\"facebook/encodec_24khz\").to(device)\n",
    "\n",
    "# Read the CSV files\n",
    "amazonas_df = pd.read_csv('./dataset/amazonas.csv')\n",
    "manaus_df = pd.read_csv('./dataset/greater_manaus.csv')\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_df = pd.concat([amazonas_df, manaus_df], ignore_index=True)\n",
    "\n",
    "# Prepare the final dataset\n",
    "final_dataset = []\n",
    "\n",
    "# Process each row in the combined dataframe\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "    common_name = row['Common Name']\n",
    "    \n",
    "    mp3_link = row['MP3 Link']\n",
    "    \n",
    "    if pd.notna(mp3_link):\n",
    "        # Download the audio file\n",
    "        file_path = download_audio(mp3_link, f\"temp_audio_{index}.mp3\")\n",
    "        \n",
    "        try:\n",
    "            # Encode the audio file\n",
    "            audio_codes = encode_wav_file(file_path)\n",
    "            decode_and_play_audio(audio_codes)\n",
    "            final_dataset.append((common_name, audio_codes))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "        finally:\n",
    "            # Remove the temporary audio file\n",
    "            os.remove(file_path)\n",
    "\n",
    "# Create a structured numpy array\n",
    "dtype = [('Common Name', 'U50'), ('Audio Codes', 'O')]\n",
    "structured_array = np.array(final_dataset, dtype=dtype)\n",
    "\n",
    "# Save the structured array to an npy file\n",
    "np.save('dataset/bird_dataset.npy', structured_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd2e5b60-ec82-4c6b-be51-5b3a5194b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "\n",
    "# Load the final_dataset.csv\n",
    "final_df = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# Calculate the frequency of each common name\n",
    "common_name_frequency = final_df['Common Name'].value_counts()\n",
    "\n",
    "# Get the top 10 most frequent common names\n",
    "top_10_common_names = common_name_frequency.head(10).index.tolist()\n",
    "\n",
    "# Create a test dataset by selecting one instance of each of the top 10 common names\n",
    "test_df = final_df[final_df['Common Name'].isin(top_10_common_names)].groupby('Common Name').head(1)\n",
    "\n",
    "# Remove these instances from the final dataset\n",
    "final_df_filtered = final_df.drop(test_df.index)\n",
    "\n",
    "# Save the updated final dataset and the test dataset to CSV files\n",
    "final_df_filtered.to_csv('dataset/train.csv', index=False)\n",
    "test_df.to_csv('dataset/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97832957-fd52-417b-9ffd-d197d742a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5339/5339 [47:00<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Function to download an audio file from a URL\n",
    "def download_audio(url, save_path):\n",
    "    url = \"https:\" + url\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    return save_path\n",
    "\n",
    "# Read the CSV files\n",
    "amazonas_df = pd.read_csv('./dataset/amazonas.csv')\n",
    "manaus_df = pd.read_csv('./dataset/greater_manaus.csv')\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_df = pd.concat([amazonas_df, manaus_df], ignore_index=True)\n",
    "\n",
    "# Prepare the final dataset\n",
    "final_dataset = []\n",
    "\n",
    "# Process each row in the combined dataframe\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "    common_name = row['Common Name']\n",
    "    mp3_link = row['MP3 Link']\n",
    "    \n",
    "    if pd.notna(mp3_link):\n",
    "        # Define the save path\n",
    "        save_path = os.path.join(\"data\", f\"audio_{index}.mp3\")\n",
    "        \n",
    "        # Download the audio file\n",
    "        file_path = download_audio(mp3_link, save_path)\n",
    "        \n",
    "        final_dataset.append({'Common Name': common_name, 'File Path': file_path})\n",
    "\n",
    "# Convert the final dataset to a DataFrame\n",
    "final_df = pd.DataFrame(final_dataset)\n",
    "\n",
    "# Save the final dataset to a CSV file\n",
    "final_df.to_csv('final_dataset_wav.csv', index=False)\n",
    "\n",
    "# Load the final_dataset.csv\n",
    "final_df = pd.read_csv('final_dataset_wav.csv')\n",
    "\n",
    "# Calculate the frequency of each common name\n",
    "common_name_frequency = final_df['Common Name'].value_counts()\n",
    "\n",
    "# Get the top 10 most frequent common names\n",
    "top_10_common_names = common_name_frequency.head(10).index.tolist()\n",
    "\n",
    "# Create a test dataset by selecting one instance of each of the top 10 common names\n",
    "test_df = final_df[final_df['Common Name'].isin(top_10_common_names)].groupby('Common Name').head(1)\n",
    "\n",
    "# Remove these instances from the final dataset\n",
    "final_df_filtered = final_df.drop(test_df.index)\n",
    "\n",
    "# Save the updated final dataset and the test dataset to CSV files\n",
    "final_df_filtered.to_csv('dataset/train_wav.csv', index=False)\n",
    "test_df.to_csv('dataset/test_wav.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e833f-3094-47bf-a664-bc4fd2448c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
