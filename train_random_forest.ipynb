{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef379de-5864-40be-9231-8d974c8b0f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Ripple\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ripple\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2001' max='2001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2001/2001 3:47:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.801000</td>\n",
       "      <td>6.682422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.631100</td>\n",
       "      <td>6.678906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.518400</td>\n",
       "      <td>6.682031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor, TrainingArguments, Trainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the Wav2Vec2 processor and model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Fixed audio length (e.g., 10 seconds)\n",
    "fixed_length = 10 * 16000  # 10 seconds * 16000 Hz\n",
    "\n",
    "# Custom dataset class\n",
    "class BirdSoundDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data[\"Encoded Labels\"] = self.label_encoder.fit_transform(self.data[\"Common Name\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx][\"File Path\"]\n",
    "        label = self.data.iloc[idx][\"Encoded Labels\"]\n",
    "        \n",
    "        # Load and preprocess the audio file\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        \n",
    "        # Ensure the audio is mono\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Ensure the audio is exactly 10 seconds\n",
    "        if waveform.size(1) > fixed_length:\n",
    "            waveform = waveform[:, :fixed_length]\n",
    "        else:\n",
    "            padding = fixed_length - waveform.size(1)\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "        \n",
    "        inputs = processor(waveform.squeeze(0), sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        return {\"input_values\": inputs.input_values.squeeze(0), \"labels\": torch.tensor(label)}\n",
    "\n",
    "# Load the data to fit the label encoder\n",
    "train_df = pd.read_csv(\"dataset/train_wav.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test_wav.csv\")\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df[\"Encoded Labels\"] = label_encoder.fit_transform(combined_df[\"Common Name\"])\n",
    "\n",
    "# Save the encoded labels back to the CSV files\n",
    "train_df[\"Encoded Labels\"] = label_encoder.transform(train_df[\"Common Name\"])\n",
    "test_df[\"Encoded Labels\"] = label_encoder.transform(test_df[\"Common Name\"])\n",
    "train_df.to_csv(\"dataset/train_final.csv\", index=False)\n",
    "test_df.to_csv(\"dataset/test_final.csv\", index=False)\n",
    "\n",
    "# Load the Wav2Vec2 model with the number of labels\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\", num_labels=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = BirdSoundDataset(csv_file=\"dataset/train_final.csv\")\n",
    "test_dataset = BirdSoundDataset(csv_file=\"dataset/test_final.csv\")\n",
    "\n",
    "# Custom collate function to handle padding\n",
    "def collate_fn(batch):\n",
    "    input_values = [item['input_values'].squeeze(0) for item in batch]  # Remove the channel dimension\n",
    "    labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)  # Convert labels to LongTensor\n",
    "    \n",
    "    # Pad the input values\n",
    "    input_values_padded = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True, padding_value=0.0)\n",
    "    return {\"input_values\": input_values_padded, \"labels\": labels}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,  # Initial learning rate\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "num_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=collate_fn,\n",
    "    optimizers=(optimizer, lr_scheduler),  # Pass the optimizer and scheduler\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./fine_tuned_model\")\n",
    "processor.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8933510-845a-4292-82b9-d53c2dae3ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and processor\n",
    "trainer.save_model(\"./fine_tuned_model\")\n",
    "processor.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effc8a17-c1d9-4501-b8c5-afd5508fb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b890316-8465-4285-988c-1e231ec7716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-05-26 22:41:19,391 - INFO - Extracting features for training set\n",
      "2024-05-26 22:41:23,359 - INFO - Batch 1/661 processed\n",
      "2024-05-26 22:41:27,331 - INFO - Batch 2/661 processed\n",
      "2024-05-26 22:41:31,209 - INFO - Batch 3/661 processed\n",
      "2024-05-26 22:41:35,094 - INFO - Batch 4/661 processed\n",
      "2024-05-26 22:41:39,049 - INFO - Batch 5/661 processed\n",
      "2024-05-26 22:41:42,932 - INFO - Batch 6/661 processed\n",
      "2024-05-26 22:41:46,796 - INFO - Batch 7/661 processed\n",
      "2024-05-26 22:41:50,729 - INFO - Batch 8/661 processed\n",
      "2024-05-26 22:41:54,724 - INFO - Batch 9/661 processed\n",
      "2024-05-26 22:41:58,635 - INFO - Batch 10/661 processed\n",
      "2024-05-26 22:42:02,515 - INFO - Batch 11/661 processed\n",
      "2024-05-26 22:42:06,435 - INFO - Batch 12/661 processed\n",
      "2024-05-26 22:42:10,337 - INFO - Batch 13/661 processed\n",
      "2024-05-26 22:42:14,184 - INFO - Batch 14/661 processed\n",
      "2024-05-26 22:42:18,029 - INFO - Batch 15/661 processed\n",
      "2024-05-26 22:42:21,931 - INFO - Batch 16/661 processed\n",
      "2024-05-26 22:42:25,876 - INFO - Batch 17/661 processed\n",
      "2024-05-26 22:42:29,744 - INFO - Batch 18/661 processed\n",
      "2024-05-26 22:42:33,638 - INFO - Batch 19/661 processed\n",
      "2024-05-26 22:42:37,534 - INFO - Batch 20/661 processed\n",
      "2024-05-26 22:42:41,378 - INFO - Batch 21/661 processed\n",
      "2024-05-26 22:42:45,279 - INFO - Batch 22/661 processed\n",
      "2024-05-26 22:42:49,248 - INFO - Batch 23/661 processed\n",
      "2024-05-26 22:42:53,128 - INFO - Batch 24/661 processed\n",
      "2024-05-26 22:42:57,019 - INFO - Batch 25/661 processed\n",
      "2024-05-26 22:43:00,896 - INFO - Batch 26/661 processed\n",
      "2024-05-26 22:43:04,774 - INFO - Batch 27/661 processed\n",
      "2024-05-26 22:43:08,663 - INFO - Batch 28/661 processed\n",
      "2024-05-26 22:43:12,498 - INFO - Batch 29/661 processed\n",
      "2024-05-26 22:43:16,333 - INFO - Batch 30/661 processed\n",
      "2024-05-26 22:43:20,178 - INFO - Batch 31/661 processed\n",
      "2024-05-26 22:43:24,010 - INFO - Batch 32/661 processed\n",
      "2024-05-26 22:43:27,855 - INFO - Batch 33/661 processed\n",
      "2024-05-26 22:43:31,691 - INFO - Batch 34/661 processed\n",
      "2024-05-26 22:43:35,528 - INFO - Batch 35/661 processed\n",
      "2024-05-26 22:43:39,372 - INFO - Batch 36/661 processed\n",
      "2024-05-26 22:43:43,216 - INFO - Batch 37/661 processed\n",
      "2024-05-26 22:43:47,057 - INFO - Batch 38/661 processed\n",
      "2024-05-26 22:43:50,899 - INFO - Batch 39/661 processed\n",
      "2024-05-26 22:43:54,735 - INFO - Batch 40/661 processed\n",
      "2024-05-26 22:43:58,588 - INFO - Batch 41/661 processed\n",
      "2024-05-26 22:44:02,436 - INFO - Batch 42/661 processed\n",
      "2024-05-26 22:44:06,276 - INFO - Batch 43/661 processed\n",
      "2024-05-26 22:44:10,133 - INFO - Batch 44/661 processed\n",
      "2024-05-26 22:44:13,980 - INFO - Batch 45/661 processed\n",
      "2024-05-26 22:44:17,818 - INFO - Batch 46/661 processed\n",
      "2024-05-26 22:44:21,663 - INFO - Batch 47/661 processed\n",
      "2024-05-26 22:44:25,504 - INFO - Batch 48/661 processed\n",
      "2024-05-26 22:44:29,355 - INFO - Batch 49/661 processed\n",
      "2024-05-26 22:44:33,203 - INFO - Batch 50/661 processed\n",
      "2024-05-26 22:44:37,046 - INFO - Batch 51/661 processed\n",
      "2024-05-26 22:44:40,894 - INFO - Batch 52/661 processed\n",
      "2024-05-26 22:44:44,738 - INFO - Batch 53/661 processed\n",
      "2024-05-26 22:44:48,581 - INFO - Batch 54/661 processed\n",
      "2024-05-26 22:44:52,424 - INFO - Batch 55/661 processed\n",
      "2024-05-26 22:44:56,267 - INFO - Batch 56/661 processed\n",
      "2024-05-26 22:45:00,143 - INFO - Batch 57/661 processed\n",
      "2024-05-26 22:45:04,025 - INFO - Batch 58/661 processed\n",
      "2024-05-26 22:45:07,876 - INFO - Batch 59/661 processed\n",
      "2024-05-26 22:45:11,723 - INFO - Batch 60/661 processed\n",
      "2024-05-26 22:45:15,565 - INFO - Batch 61/661 processed\n",
      "2024-05-26 22:45:19,403 - INFO - Batch 62/661 processed\n",
      "2024-05-26 22:45:23,240 - INFO - Batch 63/661 processed\n",
      "2024-05-26 22:45:27,090 - INFO - Batch 64/661 processed\n",
      "2024-05-26 22:45:30,945 - INFO - Batch 65/661 processed\n",
      "2024-05-26 22:45:34,797 - INFO - Batch 66/661 processed\n",
      "2024-05-26 22:45:38,636 - INFO - Batch 67/661 processed\n",
      "2024-05-26 22:45:42,485 - INFO - Batch 68/661 processed\n",
      "2024-05-26 22:45:46,328 - INFO - Batch 69/661 processed\n",
      "2024-05-26 22:45:50,172 - INFO - Batch 70/661 processed\n",
      "2024-05-26 22:45:54,013 - INFO - Batch 71/661 processed\n",
      "2024-05-26 22:45:57,854 - INFO - Batch 72/661 processed\n",
      "2024-05-26 22:46:01,738 - INFO - Batch 73/661 processed\n",
      "2024-05-26 22:46:05,873 - INFO - Batch 74/661 processed\n",
      "2024-05-26 22:46:09,886 - INFO - Batch 75/661 processed\n",
      "2024-05-26 22:46:13,753 - INFO - Batch 76/661 processed\n",
      "2024-05-26 22:46:17,782 - INFO - Batch 77/661 processed\n",
      "2024-05-26 22:46:21,790 - INFO - Batch 78/661 processed\n",
      "2024-05-26 22:46:25,678 - INFO - Batch 79/661 processed\n",
      "2024-05-26 22:46:29,626 - INFO - Batch 80/661 processed\n",
      "2024-05-26 22:46:33,461 - INFO - Batch 81/661 processed\n",
      "2024-05-26 22:46:37,503 - INFO - Batch 82/661 processed\n",
      "2024-05-26 22:46:41,548 - INFO - Batch 83/661 processed\n",
      "2024-05-26 22:46:45,582 - INFO - Batch 84/661 processed\n",
      "2024-05-26 22:46:49,603 - INFO - Batch 85/661 processed\n",
      "2024-05-26 22:46:53,770 - INFO - Batch 86/661 processed\n",
      "2024-05-26 22:46:57,890 - INFO - Batch 87/661 processed\n",
      "2024-05-26 22:47:01,832 - INFO - Batch 88/661 processed\n",
      "2024-05-26 22:47:05,854 - INFO - Batch 89/661 processed\n",
      "2024-05-26 22:47:09,952 - INFO - Batch 90/661 processed\n",
      "2024-05-26 22:47:13,973 - INFO - Batch 91/661 processed\n",
      "2024-05-26 22:47:18,006 - INFO - Batch 92/661 processed\n",
      "2024-05-26 22:47:21,916 - INFO - Batch 93/661 processed\n",
      "2024-05-26 22:47:25,825 - INFO - Batch 94/661 processed\n",
      "2024-05-26 22:47:29,742 - INFO - Batch 95/661 processed\n",
      "2024-05-26 22:47:33,735 - INFO - Batch 96/661 processed\n",
      "2024-05-26 22:47:37,639 - INFO - Batch 97/661 processed\n",
      "2024-05-26 22:47:41,618 - INFO - Batch 98/661 processed\n",
      "2024-05-26 22:47:45,713 - INFO - Batch 99/661 processed\n",
      "2024-05-26 22:47:49,819 - INFO - Batch 100/661 processed\n",
      "2024-05-26 22:47:53,961 - INFO - Batch 101/661 processed\n",
      "2024-05-26 22:47:58,171 - INFO - Batch 102/661 processed\n",
      "2024-05-26 22:48:02,311 - INFO - Batch 103/661 processed\n",
      "2024-05-26 22:48:06,445 - INFO - Batch 104/661 processed\n",
      "2024-05-26 22:48:10,578 - INFO - Batch 105/661 processed\n",
      "2024-05-26 22:48:14,617 - INFO - Batch 106/661 processed\n",
      "2024-05-26 22:48:18,815 - INFO - Batch 107/661 processed\n",
      "2024-05-26 22:48:22,930 - INFO - Batch 108/661 processed\n",
      "2024-05-26 22:48:27,053 - INFO - Batch 109/661 processed\n",
      "2024-05-26 22:48:31,196 - INFO - Batch 110/661 processed\n",
      "2024-05-26 22:48:35,381 - INFO - Batch 111/661 processed\n",
      "2024-05-26 22:48:39,532 - INFO - Batch 112/661 processed\n",
      "2024-05-26 22:48:43,651 - INFO - Batch 113/661 processed\n",
      "2024-05-26 22:48:47,743 - INFO - Batch 114/661 processed\n",
      "2024-05-26 22:48:51,867 - INFO - Batch 115/661 processed\n",
      "2024-05-26 22:48:55,973 - INFO - Batch 116/661 processed\n",
      "2024-05-26 22:49:00,086 - INFO - Batch 117/661 processed\n",
      "2024-05-26 22:49:04,194 - INFO - Batch 118/661 processed\n",
      "2024-05-26 22:49:08,305 - INFO - Batch 119/661 processed\n",
      "2024-05-26 22:49:12,414 - INFO - Batch 120/661 processed\n",
      "2024-05-26 22:49:16,565 - INFO - Batch 121/661 processed\n",
      "2024-05-26 22:49:20,690 - INFO - Batch 122/661 processed\n",
      "2024-05-26 22:49:24,842 - INFO - Batch 123/661 processed\n",
      "2024-05-26 22:49:29,137 - INFO - Batch 124/661 processed\n",
      "2024-05-26 22:49:33,306 - INFO - Batch 125/661 processed\n",
      "2024-05-26 22:49:37,490 - INFO - Batch 126/661 processed\n",
      "2024-05-26 22:49:41,864 - INFO - Batch 127/661 processed\n",
      "2024-05-26 22:49:46,019 - INFO - Batch 128/661 processed\n",
      "2024-05-26 22:49:50,034 - INFO - Batch 129/661 processed\n",
      "2024-05-26 22:49:54,063 - INFO - Batch 130/661 processed\n",
      "2024-05-26 22:49:58,258 - INFO - Batch 131/661 processed\n",
      "2024-05-26 22:50:02,413 - INFO - Batch 132/661 processed\n",
      "2024-05-26 22:50:06,618 - INFO - Batch 133/661 processed\n",
      "2024-05-26 22:50:10,931 - INFO - Batch 134/661 processed\n",
      "2024-05-26 22:50:15,160 - INFO - Batch 135/661 processed\n",
      "2024-05-26 22:50:19,333 - INFO - Batch 136/661 processed\n",
      "2024-05-26 22:50:23,502 - INFO - Batch 137/661 processed\n",
      "2024-05-26 22:50:27,676 - INFO - Batch 138/661 processed\n",
      "2024-05-26 22:50:31,850 - INFO - Batch 139/661 processed\n",
      "2024-05-26 22:50:36,035 - INFO - Batch 140/661 processed\n",
      "2024-05-26 22:50:40,216 - INFO - Batch 141/661 processed\n",
      "2024-05-26 22:50:44,387 - INFO - Batch 142/661 processed\n",
      "2024-05-26 22:50:48,567 - INFO - Batch 143/661 processed\n",
      "2024-05-26 22:50:52,738 - INFO - Batch 144/661 processed\n",
      "2024-05-26 22:50:56,909 - INFO - Batch 145/661 processed\n",
      "2024-05-26 22:51:01,090 - INFO - Batch 146/661 processed\n",
      "2024-05-26 22:51:05,272 - INFO - Batch 147/661 processed\n",
      "2024-05-26 22:51:09,448 - INFO - Batch 148/661 processed\n",
      "2024-05-26 22:51:13,638 - INFO - Batch 149/661 processed\n",
      "2024-05-26 22:51:17,821 - INFO - Batch 150/661 processed\n",
      "2024-05-26 22:51:21,995 - INFO - Batch 151/661 processed\n",
      "2024-05-26 22:51:26,162 - INFO - Batch 152/661 processed\n",
      "2024-05-26 22:51:30,357 - INFO - Batch 153/661 processed\n",
      "2024-05-26 22:51:34,542 - INFO - Batch 154/661 processed\n",
      "2024-05-26 22:51:38,713 - INFO - Batch 155/661 processed\n",
      "2024-05-26 22:51:42,889 - INFO - Batch 156/661 processed\n",
      "2024-05-26 22:51:47,056 - INFO - Batch 157/661 processed\n",
      "2024-05-26 22:51:51,236 - INFO - Batch 158/661 processed\n",
      "2024-05-26 22:51:55,414 - INFO - Batch 159/661 processed\n",
      "2024-05-26 22:51:59,596 - INFO - Batch 160/661 processed\n",
      "2024-05-26 22:52:03,779 - INFO - Batch 161/661 processed\n",
      "2024-05-26 22:52:07,952 - INFO - Batch 162/661 processed\n",
      "2024-05-26 22:52:12,133 - INFO - Batch 163/661 processed\n",
      "2024-05-26 22:52:16,320 - INFO - Batch 164/661 processed\n",
      "2024-05-26 22:52:20,487 - INFO - Batch 165/661 processed\n",
      "2024-05-26 22:52:24,657 - INFO - Batch 166/661 processed\n",
      "2024-05-26 22:52:28,834 - INFO - Batch 167/661 processed\n",
      "2024-05-26 22:52:33,014 - INFO - Batch 168/661 processed\n",
      "2024-05-26 22:52:37,199 - INFO - Batch 169/661 processed\n",
      "2024-05-26 22:52:41,391 - INFO - Batch 170/661 processed\n",
      "2024-05-26 22:52:45,570 - INFO - Batch 171/661 processed\n",
      "2024-05-26 22:52:49,742 - INFO - Batch 172/661 processed\n",
      "2024-05-26 22:52:53,924 - INFO - Batch 173/661 processed\n",
      "2024-05-26 22:52:58,092 - INFO - Batch 174/661 processed\n",
      "2024-05-26 22:53:02,279 - INFO - Batch 175/661 processed\n",
      "2024-05-26 22:53:06,456 - INFO - Batch 176/661 processed\n",
      "2024-05-26 22:53:10,646 - INFO - Batch 177/661 processed\n",
      "2024-05-26 22:53:14,829 - INFO - Batch 178/661 processed\n",
      "2024-05-26 22:53:19,034 - INFO - Batch 179/661 processed\n",
      "2024-05-26 22:53:23,210 - INFO - Batch 180/661 processed\n",
      "2024-05-26 22:53:27,430 - INFO - Batch 181/661 processed\n",
      "2024-05-26 22:53:31,612 - INFO - Batch 182/661 processed\n",
      "2024-05-26 22:53:35,803 - INFO - Batch 183/661 processed\n",
      "2024-05-26 22:53:39,992 - INFO - Batch 184/661 processed\n",
      "2024-05-26 22:53:44,180 - INFO - Batch 185/661 processed\n",
      "2024-05-26 22:53:48,357 - INFO - Batch 186/661 processed\n",
      "2024-05-26 22:53:52,542 - INFO - Batch 187/661 processed\n",
      "2024-05-26 22:53:56,721 - INFO - Batch 188/661 processed\n",
      "2024-05-26 22:54:00,903 - INFO - Batch 189/661 processed\n",
      "2024-05-26 22:54:05,077 - INFO - Batch 190/661 processed\n",
      "2024-05-26 22:54:09,263 - INFO - Batch 191/661 processed\n",
      "2024-05-26 22:54:13,476 - INFO - Batch 192/661 processed\n",
      "2024-05-26 22:54:17,662 - INFO - Batch 193/661 processed\n",
      "2024-05-26 22:54:21,832 - INFO - Batch 194/661 processed\n",
      "2024-05-26 22:54:26,014 - INFO - Batch 195/661 processed\n",
      "2024-05-26 22:54:30,194 - INFO - Batch 196/661 processed\n",
      "2024-05-26 22:54:34,382 - INFO - Batch 197/661 processed\n",
      "2024-05-26 22:54:38,562 - INFO - Batch 198/661 processed\n",
      "2024-05-26 22:54:42,763 - INFO - Batch 199/661 processed\n",
      "2024-05-26 22:54:46,964 - INFO - Batch 200/661 processed\n",
      "2024-05-26 22:54:51,154 - INFO - Batch 201/661 processed\n",
      "2024-05-26 22:54:55,339 - INFO - Batch 202/661 processed\n",
      "2024-05-26 22:54:59,537 - INFO - Batch 203/661 processed\n",
      "2024-05-26 22:55:03,789 - INFO - Batch 204/661 processed\n",
      "2024-05-26 22:55:08,003 - INFO - Batch 205/661 processed\n",
      "2024-05-26 22:55:12,188 - INFO - Batch 206/661 processed\n",
      "2024-05-26 22:55:16,376 - INFO - Batch 207/661 processed\n",
      "2024-05-26 22:55:20,569 - INFO - Batch 208/661 processed\n",
      "2024-05-26 22:55:24,752 - INFO - Batch 209/661 processed\n",
      "2024-05-26 22:55:28,941 - INFO - Batch 210/661 processed\n",
      "2024-05-26 22:55:33,137 - INFO - Batch 211/661 processed\n",
      "2024-05-26 22:55:37,336 - INFO - Batch 212/661 processed\n",
      "2024-05-26 22:55:41,516 - INFO - Batch 213/661 processed\n",
      "2024-05-26 22:55:45,699 - INFO - Batch 214/661 processed\n",
      "2024-05-26 22:55:49,876 - INFO - Batch 215/661 processed\n",
      "2024-05-26 22:55:54,064 - INFO - Batch 216/661 processed\n",
      "2024-05-26 22:55:58,238 - INFO - Batch 217/661 processed\n",
      "2024-05-26 22:56:02,435 - INFO - Batch 218/661 processed\n",
      "2024-05-26 22:56:06,625 - INFO - Batch 219/661 processed\n",
      "2024-05-26 22:56:10,806 - INFO - Batch 220/661 processed\n",
      "2024-05-26 22:56:14,991 - INFO - Batch 221/661 processed\n",
      "2024-05-26 22:56:19,158 - INFO - Batch 222/661 processed\n",
      "2024-05-26 22:56:23,336 - INFO - Batch 223/661 processed\n",
      "2024-05-26 22:56:27,506 - INFO - Batch 224/661 processed\n",
      "2024-05-26 22:56:31,687 - INFO - Batch 225/661 processed\n",
      "2024-05-26 22:56:35,868 - INFO - Batch 226/661 processed\n",
      "2024-05-26 22:56:40,047 - INFO - Batch 227/661 processed\n",
      "2024-05-26 22:56:44,229 - INFO - Batch 228/661 processed\n",
      "2024-05-26 22:56:48,397 - INFO - Batch 229/661 processed\n",
      "2024-05-26 22:56:52,623 - INFO - Batch 230/661 processed\n",
      "2024-05-26 22:56:56,805 - INFO - Batch 231/661 processed\n",
      "2024-05-26 22:57:00,982 - INFO - Batch 232/661 processed\n",
      "2024-05-26 22:57:05,148 - INFO - Batch 233/661 processed\n",
      "2024-05-26 22:57:09,339 - INFO - Batch 234/661 processed\n",
      "2024-05-26 22:57:13,522 - INFO - Batch 235/661 processed\n",
      "2024-05-26 22:57:17,699 - INFO - Batch 236/661 processed\n",
      "2024-05-26 22:57:21,866 - INFO - Batch 237/661 processed\n",
      "2024-05-26 22:57:26,032 - INFO - Batch 238/661 processed\n",
      "2024-05-26 22:57:30,222 - INFO - Batch 239/661 processed\n",
      "2024-05-26 22:57:34,397 - INFO - Batch 240/661 processed\n",
      "2024-05-26 22:57:38,571 - INFO - Batch 241/661 processed\n",
      "2024-05-26 22:57:42,749 - INFO - Batch 242/661 processed\n",
      "2024-05-26 22:57:46,919 - INFO - Batch 243/661 processed\n",
      "2024-05-26 22:57:51,087 - INFO - Batch 244/661 processed\n",
      "2024-05-26 22:57:55,263 - INFO - Batch 245/661 processed\n",
      "2024-05-26 22:57:59,447 - INFO - Batch 246/661 processed\n",
      "2024-05-26 22:58:03,631 - INFO - Batch 247/661 processed\n",
      "2024-05-26 22:58:07,801 - INFO - Batch 248/661 processed\n",
      "2024-05-26 22:58:11,975 - INFO - Batch 249/661 processed\n",
      "2024-05-26 22:58:16,154 - INFO - Batch 250/661 processed\n",
      "2024-05-26 22:58:20,326 - INFO - Batch 251/661 processed\n",
      "2024-05-26 22:58:24,504 - INFO - Batch 252/661 processed\n",
      "2024-05-26 22:58:28,678 - INFO - Batch 253/661 processed\n",
      "2024-05-26 22:58:32,849 - INFO - Batch 254/661 processed\n",
      "2024-05-26 22:58:37,036 - INFO - Batch 255/661 processed\n",
      "2024-05-26 22:58:41,275 - INFO - Batch 256/661 processed\n",
      "2024-05-26 22:58:45,474 - INFO - Batch 257/661 processed\n",
      "2024-05-26 22:58:49,655 - INFO - Batch 258/661 processed\n",
      "2024-05-26 22:58:53,827 - INFO - Batch 259/661 processed\n",
      "2024-05-26 22:58:58,005 - INFO - Batch 260/661 processed\n",
      "2024-05-26 22:59:02,178 - INFO - Batch 261/661 processed\n",
      "2024-05-26 22:59:06,347 - INFO - Batch 262/661 processed\n",
      "2024-05-26 22:59:10,511 - INFO - Batch 263/661 processed\n",
      "2024-05-26 22:59:14,692 - INFO - Batch 264/661 processed\n",
      "2024-05-26 22:59:18,869 - INFO - Batch 265/661 processed\n",
      "2024-05-26 22:59:23,084 - INFO - Batch 266/661 processed\n",
      "2024-05-26 22:59:27,279 - INFO - Batch 267/661 processed\n",
      "2024-05-26 22:59:31,454 - INFO - Batch 268/661 processed\n",
      "2024-05-26 22:59:35,676 - INFO - Batch 269/661 processed\n",
      "2024-05-26 22:59:39,842 - INFO - Batch 270/661 processed\n",
      "2024-05-26 22:59:43,954 - INFO - Batch 271/661 processed\n",
      "2024-05-26 22:59:48,188 - INFO - Batch 272/661 processed\n",
      "2024-05-26 22:59:52,471 - INFO - Batch 273/661 processed\n",
      "2024-05-26 22:59:56,721 - INFO - Batch 274/661 processed\n",
      "2024-05-26 23:00:00,945 - INFO - Batch 275/661 processed\n",
      "2024-05-26 23:00:05,102 - INFO - Batch 276/661 processed\n",
      "2024-05-26 23:00:09,431 - INFO - Batch 277/661 processed\n",
      "2024-05-26 23:00:14,014 - INFO - Batch 278/661 processed\n",
      "2024-05-26 23:00:18,389 - INFO - Batch 279/661 processed\n",
      "2024-05-26 23:00:22,646 - INFO - Batch 280/661 processed\n",
      "2024-05-26 23:00:26,850 - INFO - Batch 281/661 processed\n",
      "2024-05-26 23:00:30,947 - INFO - Batch 282/661 processed\n",
      "2024-05-26 23:00:35,010 - INFO - Batch 283/661 processed\n",
      "2024-05-26 23:00:39,067 - INFO - Batch 284/661 processed\n",
      "2024-05-26 23:00:43,266 - INFO - Batch 285/661 processed\n",
      "2024-05-26 23:00:47,685 - INFO - Batch 286/661 processed\n",
      "2024-05-26 23:00:52,075 - INFO - Batch 287/661 processed\n",
      "2024-05-26 23:00:56,409 - INFO - Batch 288/661 processed\n",
      "2024-05-26 23:01:00,782 - INFO - Batch 289/661 processed\n",
      "2024-05-26 23:01:05,122 - INFO - Batch 290/661 processed\n",
      "2024-05-26 23:01:09,494 - INFO - Batch 291/661 processed\n",
      "2024-05-26 23:01:13,961 - INFO - Batch 292/661 processed\n",
      "2024-05-26 23:01:18,188 - INFO - Batch 293/661 processed\n",
      "2024-05-26 23:01:22,404 - INFO - Batch 294/661 processed\n",
      "2024-05-26 23:01:26,610 - INFO - Batch 295/661 processed\n",
      "2024-05-26 23:01:30,832 - INFO - Batch 296/661 processed\n",
      "2024-05-26 23:01:35,038 - INFO - Batch 297/661 processed\n",
      "2024-05-26 23:01:39,382 - INFO - Batch 298/661 processed\n",
      "2024-05-26 23:01:43,607 - INFO - Batch 299/661 processed\n",
      "2024-05-26 23:01:47,826 - INFO - Batch 300/661 processed\n",
      "2024-05-26 23:01:52,033 - INFO - Batch 301/661 processed\n",
      "2024-05-26 23:01:56,319 - INFO - Batch 302/661 processed\n",
      "2024-05-26 23:02:00,785 - INFO - Batch 303/661 processed\n",
      "2024-05-26 23:02:05,040 - INFO - Batch 304/661 processed\n",
      "2024-05-26 23:02:09,299 - INFO - Batch 305/661 processed\n",
      "2024-05-26 23:02:13,386 - INFO - Batch 306/661 processed\n",
      "2024-05-26 23:02:17,663 - INFO - Batch 307/661 processed\n",
      "2024-05-26 23:02:21,842 - INFO - Batch 308/661 processed\n",
      "2024-05-26 23:02:26,241 - INFO - Batch 309/661 processed\n",
      "2024-05-26 23:02:30,697 - INFO - Batch 310/661 processed\n",
      "2024-05-26 23:02:34,868 - INFO - Batch 311/661 processed\n",
      "2024-05-26 23:02:39,124 - INFO - Batch 312/661 processed\n",
      "2024-05-26 23:02:43,488 - INFO - Batch 313/661 processed\n",
      "2024-05-26 23:02:48,008 - INFO - Batch 314/661 processed\n",
      "2024-05-26 23:02:52,480 - INFO - Batch 315/661 processed\n",
      "2024-05-26 23:02:56,797 - INFO - Batch 316/661 processed\n",
      "2024-05-26 23:03:00,973 - INFO - Batch 317/661 processed\n",
      "2024-05-26 23:03:05,611 - INFO - Batch 318/661 processed\n",
      "2024-05-26 23:03:10,021 - INFO - Batch 319/661 processed\n",
      "2024-05-26 23:03:14,394 - INFO - Batch 320/661 processed\n",
      "2024-05-26 23:03:18,836 - INFO - Batch 321/661 processed\n",
      "2024-05-26 23:03:23,282 - INFO - Batch 322/661 processed\n",
      "2024-05-26 23:03:27,554 - INFO - Batch 323/661 processed\n",
      "2024-05-26 23:03:31,860 - INFO - Batch 324/661 processed\n",
      "2024-05-26 23:03:35,935 - INFO - Batch 325/661 processed\n",
      "2024-05-26 23:03:40,261 - INFO - Batch 326/661 processed\n",
      "2024-05-26 23:03:44,678 - INFO - Batch 327/661 processed\n",
      "2024-05-26 23:03:48,943 - INFO - Batch 328/661 processed\n",
      "2024-05-26 23:03:53,238 - INFO - Batch 329/661 processed\n",
      "2024-05-26 23:03:57,884 - INFO - Batch 330/661 processed\n",
      "2024-05-26 23:04:02,051 - INFO - Batch 331/661 processed\n",
      "2024-05-26 23:04:06,400 - INFO - Batch 332/661 processed\n",
      "2024-05-26 23:04:10,787 - INFO - Batch 333/661 processed\n",
      "2024-05-26 23:04:15,122 - INFO - Batch 334/661 processed\n",
      "2024-05-26 23:04:19,254 - INFO - Batch 335/661 processed\n",
      "2024-05-26 23:04:23,792 - INFO - Batch 336/661 processed\n",
      "2024-05-26 23:04:28,321 - INFO - Batch 337/661 processed\n",
      "2024-05-26 23:04:32,573 - INFO - Batch 338/661 processed\n",
      "2024-05-26 23:04:36,723 - INFO - Batch 339/661 processed\n",
      "2024-05-26 23:04:40,996 - INFO - Batch 340/661 processed\n",
      "2024-05-26 23:04:45,196 - INFO - Batch 341/661 processed\n",
      "2024-05-26 23:04:49,743 - INFO - Batch 342/661 processed\n",
      "2024-05-26 23:04:54,024 - INFO - Batch 343/661 processed\n",
      "2024-05-26 23:04:58,224 - INFO - Batch 344/661 processed\n",
      "2024-05-26 23:05:02,449 - INFO - Batch 345/661 processed\n",
      "2024-05-26 23:05:06,587 - INFO - Batch 346/661 processed\n",
      "2024-05-26 23:05:10,717 - INFO - Batch 347/661 processed\n",
      "2024-05-26 23:05:14,879 - INFO - Batch 348/661 processed\n",
      "2024-05-26 23:05:19,029 - INFO - Batch 349/661 processed\n",
      "2024-05-26 23:05:23,093 - INFO - Batch 350/661 processed\n",
      "2024-05-26 23:05:27,174 - INFO - Batch 351/661 processed\n",
      "2024-05-26 23:05:31,247 - INFO - Batch 352/661 processed\n",
      "2024-05-26 23:05:35,325 - INFO - Batch 353/661 processed\n",
      "2024-05-26 23:05:39,674 - INFO - Batch 354/661 processed\n",
      "2024-05-26 23:05:43,869 - INFO - Batch 355/661 processed\n",
      "2024-05-26 23:05:48,019 - INFO - Batch 356/661 processed\n",
      "2024-05-26 23:05:52,183 - INFO - Batch 357/661 processed\n",
      "2024-05-26 23:05:56,392 - INFO - Batch 358/661 processed\n",
      "2024-05-26 23:06:00,526 - INFO - Batch 359/661 processed\n",
      "2024-05-26 23:06:04,626 - INFO - Batch 360/661 processed\n",
      "2024-05-26 23:06:08,687 - INFO - Batch 361/661 processed\n",
      "2024-05-26 23:06:12,742 - INFO - Batch 362/661 processed\n",
      "2024-05-26 23:06:16,787 - INFO - Batch 363/661 processed\n",
      "2024-05-26 23:06:20,841 - INFO - Batch 364/661 processed\n",
      "2024-05-26 23:06:24,906 - INFO - Batch 365/661 processed\n",
      "2024-05-26 23:06:28,979 - INFO - Batch 366/661 processed\n",
      "2024-05-26 23:06:33,044 - INFO - Batch 367/661 processed\n",
      "2024-05-26 23:06:37,141 - INFO - Batch 368/661 processed\n",
      "2024-05-26 23:06:41,241 - INFO - Batch 369/661 processed\n",
      "2024-05-26 23:06:45,333 - INFO - Batch 370/661 processed\n",
      "2024-05-26 23:06:49,378 - INFO - Batch 371/661 processed\n",
      "2024-05-26 23:06:53,423 - INFO - Batch 372/661 processed\n",
      "2024-05-26 23:06:57,474 - INFO - Batch 373/661 processed\n",
      "2024-05-26 23:07:01,564 - INFO - Batch 374/661 processed\n",
      "2024-05-26 23:07:05,641 - INFO - Batch 375/661 processed\n",
      "2024-05-26 23:07:09,717 - INFO - Batch 376/661 processed\n",
      "2024-05-26 23:07:13,792 - INFO - Batch 377/661 processed\n",
      "2024-05-26 23:07:17,884 - INFO - Batch 378/661 processed\n",
      "2024-05-26 23:07:21,981 - INFO - Batch 379/661 processed\n",
      "2024-05-26 23:07:26,045 - INFO - Batch 380/661 processed\n",
      "2024-05-26 23:07:30,145 - INFO - Batch 381/661 processed\n",
      "2024-05-26 23:07:34,253 - INFO - Batch 382/661 processed\n",
      "2024-05-26 23:07:38,453 - INFO - Batch 383/661 processed\n",
      "2024-05-26 23:07:42,582 - INFO - Batch 384/661 processed\n",
      "2024-05-26 23:07:46,667 - INFO - Batch 385/661 processed\n",
      "2024-05-26 23:07:50,776 - INFO - Batch 386/661 processed\n",
      "2024-05-26 23:07:54,895 - INFO - Batch 387/661 processed\n",
      "2024-05-26 23:07:59,017 - INFO - Batch 388/661 processed\n",
      "2024-05-26 23:08:03,212 - INFO - Batch 389/661 processed\n",
      "2024-05-26 23:08:07,456 - INFO - Batch 390/661 processed\n",
      "2024-05-26 23:08:11,668 - INFO - Batch 391/661 processed\n",
      "2024-05-26 23:08:15,839 - INFO - Batch 392/661 processed\n",
      "2024-05-26 23:08:19,985 - INFO - Batch 393/661 processed\n",
      "2024-05-26 23:08:24,194 - INFO - Batch 394/661 processed\n",
      "2024-05-26 23:08:28,497 - INFO - Batch 395/661 processed\n",
      "2024-05-26 23:08:32,767 - INFO - Batch 396/661 processed\n",
      "2024-05-26 23:08:37,073 - INFO - Batch 397/661 processed\n",
      "2024-05-26 23:08:41,192 - INFO - Batch 398/661 processed\n",
      "2024-05-26 23:08:45,275 - INFO - Batch 399/661 processed\n",
      "2024-05-26 23:08:49,339 - INFO - Batch 400/661 processed\n",
      "2024-05-26 23:08:53,418 - INFO - Batch 401/661 processed\n",
      "2024-05-26 23:08:57,456 - INFO - Batch 402/661 processed\n",
      "2024-05-26 23:09:01,507 - INFO - Batch 403/661 processed\n",
      "2024-05-26 23:09:05,539 - INFO - Batch 404/661 processed\n",
      "2024-05-26 23:09:09,574 - INFO - Batch 405/661 processed\n",
      "2024-05-26 23:09:13,631 - INFO - Batch 406/661 processed\n",
      "2024-05-26 23:09:17,663 - INFO - Batch 407/661 processed\n",
      "2024-05-26 23:09:21,712 - INFO - Batch 408/661 processed\n",
      "2024-05-26 23:09:25,871 - INFO - Batch 409/661 processed\n",
      "2024-05-26 23:09:29,946 - INFO - Batch 410/661 processed\n",
      "2024-05-26 23:09:33,986 - INFO - Batch 411/661 processed\n",
      "2024-05-26 23:09:38,032 - INFO - Batch 412/661 processed\n",
      "2024-05-26 23:09:42,070 - INFO - Batch 413/661 processed\n",
      "2024-05-26 23:09:46,325 - INFO - Batch 414/661 processed\n",
      "2024-05-26 23:09:50,480 - INFO - Batch 415/661 processed\n",
      "2024-05-26 23:09:54,583 - INFO - Batch 416/661 processed\n",
      "2024-05-26 23:09:58,983 - INFO - Batch 417/661 processed\n",
      "2024-05-26 23:10:03,311 - INFO - Batch 418/661 processed\n",
      "2024-05-26 23:10:07,485 - INFO - Batch 419/661 processed\n",
      "2024-05-26 23:10:11,712 - INFO - Batch 420/661 processed\n",
      "2024-05-26 23:10:16,060 - INFO - Batch 421/661 processed\n",
      "2024-05-26 23:10:20,364 - INFO - Batch 422/661 processed\n",
      "2024-05-26 23:10:24,498 - INFO - Batch 423/661 processed\n",
      "2024-05-26 23:10:28,620 - INFO - Batch 424/661 processed\n",
      "2024-05-26 23:10:32,804 - INFO - Batch 425/661 processed\n",
      "2024-05-26 23:10:37,156 - INFO - Batch 426/661 processed\n",
      "2024-05-26 23:10:41,421 - INFO - Batch 427/661 processed\n",
      "2024-05-26 23:10:45,714 - INFO - Batch 428/661 processed\n",
      "2024-05-26 23:10:49,966 - INFO - Batch 429/661 processed\n",
      "2024-05-26 23:10:54,202 - INFO - Batch 430/661 processed\n",
      "2024-05-26 23:10:58,486 - INFO - Batch 431/661 processed\n",
      "2024-05-26 23:11:02,795 - INFO - Batch 432/661 processed\n",
      "2024-05-26 23:11:07,204 - INFO - Batch 433/661 processed\n",
      "2024-05-26 23:11:11,414 - INFO - Batch 434/661 processed\n",
      "2024-05-26 23:11:15,766 - INFO - Batch 435/661 processed\n",
      "2024-05-26 23:11:19,904 - INFO - Batch 436/661 processed\n",
      "2024-05-26 23:11:23,966 - INFO - Batch 437/661 processed\n",
      "2024-05-26 23:11:28,023 - INFO - Batch 438/661 processed\n",
      "2024-05-26 23:11:32,168 - INFO - Batch 439/661 processed\n",
      "2024-05-26 23:11:36,299 - INFO - Batch 440/661 processed\n",
      "2024-05-26 23:11:40,365 - INFO - Batch 441/661 processed\n",
      "2024-05-26 23:11:44,408 - INFO - Batch 442/661 processed\n",
      "2024-05-26 23:11:48,453 - INFO - Batch 443/661 processed\n",
      "2024-05-26 23:11:52,588 - INFO - Batch 444/661 processed\n",
      "2024-05-26 23:11:56,631 - INFO - Batch 445/661 processed\n",
      "2024-05-26 23:12:00,674 - INFO - Batch 446/661 processed\n",
      "2024-05-26 23:12:04,715 - INFO - Batch 447/661 processed\n",
      "2024-05-26 23:12:08,810 - INFO - Batch 448/661 processed\n",
      "2024-05-26 23:12:12,872 - INFO - Batch 449/661 processed\n",
      "2024-05-26 23:12:16,918 - INFO - Batch 450/661 processed\n",
      "2024-05-26 23:12:20,965 - INFO - Batch 451/661 processed\n",
      "2024-05-26 23:12:25,002 - INFO - Batch 452/661 processed\n",
      "2024-05-26 23:12:29,043 - INFO - Batch 453/661 processed\n",
      "2024-05-26 23:12:33,093 - INFO - Batch 454/661 processed\n",
      "2024-05-26 23:12:37,136 - INFO - Batch 455/661 processed\n",
      "2024-05-26 23:12:41,175 - INFO - Batch 456/661 processed\n",
      "2024-05-26 23:12:45,222 - INFO - Batch 457/661 processed\n",
      "2024-05-26 23:12:49,261 - INFO - Batch 458/661 processed\n",
      "2024-05-26 23:12:53,308 - INFO - Batch 459/661 processed\n",
      "2024-05-26 23:12:57,353 - INFO - Batch 460/661 processed\n",
      "2024-05-26 23:13:01,398 - INFO - Batch 461/661 processed\n",
      "2024-05-26 23:13:05,434 - INFO - Batch 462/661 processed\n",
      "2024-05-26 23:13:09,468 - INFO - Batch 463/661 processed\n",
      "2024-05-26 23:13:13,494 - INFO - Batch 464/661 processed\n",
      "2024-05-26 23:13:17,526 - INFO - Batch 465/661 processed\n",
      "2024-05-26 23:13:21,538 - INFO - Batch 466/661 processed\n",
      "2024-05-26 23:13:25,555 - INFO - Batch 467/661 processed\n",
      "2024-05-26 23:13:29,576 - INFO - Batch 468/661 processed\n",
      "2024-05-26 23:13:33,595 - INFO - Batch 469/661 processed\n",
      "2024-05-26 23:13:37,601 - INFO - Batch 470/661 processed\n",
      "2024-05-26 23:13:41,621 - INFO - Batch 471/661 processed\n",
      "2024-05-26 23:13:45,632 - INFO - Batch 472/661 processed\n",
      "2024-05-26 23:13:49,636 - INFO - Batch 473/661 processed\n",
      "2024-05-26 23:13:53,640 - INFO - Batch 474/661 processed\n",
      "2024-05-26 23:13:57,633 - INFO - Batch 475/661 processed\n",
      "2024-05-26 23:14:01,638 - INFO - Batch 476/661 processed\n",
      "2024-05-26 23:14:05,645 - INFO - Batch 477/661 processed\n",
      "2024-05-26 23:14:09,642 - INFO - Batch 478/661 processed\n",
      "2024-05-26 23:14:13,641 - INFO - Batch 479/661 processed\n",
      "2024-05-26 23:14:17,646 - INFO - Batch 480/661 processed\n",
      "2024-05-26 23:14:21,639 - INFO - Batch 481/661 processed\n",
      "2024-05-26 23:14:25,631 - INFO - Batch 482/661 processed\n",
      "2024-05-26 23:14:29,618 - INFO - Batch 483/661 processed\n",
      "2024-05-26 23:14:33,611 - INFO - Batch 484/661 processed\n",
      "2024-05-26 23:14:37,603 - INFO - Batch 485/661 processed\n",
      "2024-05-26 23:14:41,595 - INFO - Batch 486/661 processed\n",
      "2024-05-26 23:14:45,584 - INFO - Batch 487/661 processed\n",
      "2024-05-26 23:14:49,604 - INFO - Batch 488/661 processed\n",
      "2024-05-26 23:14:53,604 - INFO - Batch 489/661 processed\n",
      "2024-05-26 23:14:57,600 - INFO - Batch 490/661 processed\n",
      "2024-05-26 23:15:01,622 - INFO - Batch 491/661 processed\n",
      "2024-05-26 23:15:05,618 - INFO - Batch 492/661 processed\n",
      "2024-05-26 23:15:09,613 - INFO - Batch 493/661 processed\n",
      "2024-05-26 23:15:13,611 - INFO - Batch 494/661 processed\n",
      "2024-05-26 23:15:17,606 - INFO - Batch 495/661 processed\n",
      "2024-05-26 23:15:21,594 - INFO - Batch 496/661 processed\n",
      "2024-05-26 23:15:25,581 - INFO - Batch 497/661 processed\n",
      "2024-05-26 23:15:29,596 - INFO - Batch 498/661 processed\n",
      "2024-05-26 23:15:33,594 - INFO - Batch 499/661 processed\n",
      "2024-05-26 23:15:37,597 - INFO - Batch 500/661 processed\n",
      "2024-05-26 23:15:41,595 - INFO - Batch 501/661 processed\n",
      "2024-05-26 23:15:45,586 - INFO - Batch 502/661 processed\n",
      "2024-05-26 23:15:49,578 - INFO - Batch 503/661 processed\n",
      "2024-05-26 23:15:53,568 - INFO - Batch 504/661 processed\n",
      "2024-05-26 23:15:57,558 - INFO - Batch 505/661 processed\n",
      "2024-05-26 23:16:01,561 - INFO - Batch 506/661 processed\n",
      "2024-05-26 23:16:05,572 - INFO - Batch 507/661 processed\n",
      "2024-05-26 23:16:09,562 - INFO - Batch 508/661 processed\n",
      "2024-05-26 23:16:13,666 - INFO - Batch 509/661 processed\n",
      "2024-05-26 23:16:17,717 - INFO - Batch 510/661 processed\n",
      "2024-05-26 23:16:21,738 - INFO - Batch 511/661 processed\n",
      "2024-05-26 23:16:25,780 - INFO - Batch 512/661 processed\n",
      "2024-05-26 23:16:29,910 - INFO - Batch 513/661 processed\n",
      "2024-05-26 23:16:34,068 - INFO - Batch 514/661 processed\n",
      "2024-05-26 23:16:38,189 - INFO - Batch 515/661 processed\n",
      "2024-05-26 23:16:42,221 - INFO - Batch 516/661 processed\n",
      "2024-05-26 23:16:46,241 - INFO - Batch 517/661 processed\n",
      "2024-05-26 23:16:50,272 - INFO - Batch 518/661 processed\n",
      "2024-05-26 23:16:54,298 - INFO - Batch 519/661 processed\n",
      "2024-05-26 23:16:58,318 - INFO - Batch 520/661 processed\n",
      "2024-05-26 23:17:02,350 - INFO - Batch 521/661 processed\n",
      "2024-05-26 23:17:06,385 - INFO - Batch 522/661 processed\n",
      "2024-05-26 23:17:10,429 - INFO - Batch 523/661 processed\n",
      "2024-05-26 23:17:14,449 - INFO - Batch 524/661 processed\n",
      "2024-05-26 23:17:18,471 - INFO - Batch 525/661 processed\n",
      "2024-05-26 23:17:22,495 - INFO - Batch 526/661 processed\n",
      "2024-05-26 23:17:26,513 - INFO - Batch 527/661 processed\n",
      "2024-05-26 23:17:30,539 - INFO - Batch 528/661 processed\n",
      "2024-05-26 23:17:34,558 - INFO - Batch 529/661 processed\n",
      "2024-05-26 23:17:38,586 - INFO - Batch 530/661 processed\n",
      "2024-05-26 23:17:42,627 - INFO - Batch 531/661 processed\n",
      "2024-05-26 23:17:46,643 - INFO - Batch 532/661 processed\n",
      "2024-05-26 23:17:50,660 - INFO - Batch 533/661 processed\n",
      "2024-05-26 23:17:54,678 - INFO - Batch 534/661 processed\n",
      "2024-05-26 23:17:58,698 - INFO - Batch 535/661 processed\n",
      "2024-05-26 23:18:02,727 - INFO - Batch 536/661 processed\n",
      "2024-05-26 23:18:06,751 - INFO - Batch 537/661 processed\n",
      "2024-05-26 23:18:10,782 - INFO - Batch 538/661 processed\n",
      "2024-05-26 23:18:14,821 - INFO - Batch 539/661 processed\n",
      "2024-05-26 23:18:18,832 - INFO - Batch 540/661 processed\n",
      "2024-05-26 23:18:22,852 - INFO - Batch 541/661 processed\n",
      "2024-05-26 23:18:26,870 - INFO - Batch 542/661 processed\n",
      "2024-05-26 23:18:30,894 - INFO - Batch 543/661 processed\n",
      "2024-05-26 23:18:34,906 - INFO - Batch 544/661 processed\n",
      "2024-05-26 23:18:38,929 - INFO - Batch 545/661 processed\n",
      "2024-05-26 23:18:42,952 - INFO - Batch 546/661 processed\n",
      "2024-05-26 23:18:46,981 - INFO - Batch 547/661 processed\n",
      "2024-05-26 23:18:51,004 - INFO - Batch 548/661 processed\n",
      "2024-05-26 23:18:55,013 - INFO - Batch 549/661 processed\n",
      "2024-05-26 23:18:59,033 - INFO - Batch 550/661 processed\n",
      "2024-05-26 23:19:03,064 - INFO - Batch 551/661 processed\n",
      "2024-05-26 23:19:07,090 - INFO - Batch 552/661 processed\n",
      "2024-05-26 23:19:11,112 - INFO - Batch 553/661 processed\n",
      "2024-05-26 23:19:15,136 - INFO - Batch 554/661 processed\n",
      "2024-05-26 23:19:19,174 - INFO - Batch 555/661 processed\n",
      "2024-05-26 23:19:23,207 - INFO - Batch 556/661 processed\n",
      "2024-05-26 23:19:27,236 - INFO - Batch 557/661 processed\n",
      "2024-05-26 23:19:31,256 - INFO - Batch 558/661 processed\n",
      "2024-05-26 23:19:35,281 - INFO - Batch 559/661 processed\n",
      "2024-05-26 23:19:39,304 - INFO - Batch 560/661 processed\n",
      "2024-05-26 23:19:43,339 - INFO - Batch 561/661 processed\n",
      "2024-05-26 23:19:47,367 - INFO - Batch 562/661 processed\n",
      "2024-05-26 23:19:51,412 - INFO - Batch 563/661 processed\n",
      "2024-05-26 23:19:55,430 - INFO - Batch 564/661 processed\n",
      "2024-05-26 23:19:59,463 - INFO - Batch 565/661 processed\n",
      "2024-05-26 23:20:03,495 - INFO - Batch 566/661 processed\n",
      "2024-05-26 23:20:07,515 - INFO - Batch 567/661 processed\n",
      "2024-05-26 23:20:11,540 - INFO - Batch 568/661 processed\n",
      "2024-05-26 23:20:15,571 - INFO - Batch 569/661 processed\n",
      "2024-05-26 23:20:19,585 - INFO - Batch 570/661 processed\n",
      "2024-05-26 23:20:23,628 - INFO - Batch 571/661 processed\n",
      "2024-05-26 23:20:27,647 - INFO - Batch 572/661 processed\n",
      "2024-05-26 23:20:31,670 - INFO - Batch 573/661 processed\n",
      "2024-05-26 23:20:35,692 - INFO - Batch 574/661 processed\n",
      "2024-05-26 23:20:39,729 - INFO - Batch 575/661 processed\n",
      "2024-05-26 23:20:43,754 - INFO - Batch 576/661 processed\n",
      "2024-05-26 23:20:47,772 - INFO - Batch 577/661 processed\n",
      "2024-05-26 23:20:51,791 - INFO - Batch 578/661 processed\n",
      "2024-05-26 23:20:55,819 - INFO - Batch 579/661 processed\n",
      "2024-05-26 23:20:59,832 - INFO - Batch 580/661 processed\n",
      "2024-05-26 23:21:03,876 - INFO - Batch 581/661 processed\n",
      "2024-05-26 23:21:07,914 - INFO - Batch 582/661 processed\n",
      "2024-05-26 23:21:11,932 - INFO - Batch 583/661 processed\n",
      "2024-05-26 23:21:15,958 - INFO - Batch 584/661 processed\n",
      "2024-05-26 23:21:19,980 - INFO - Batch 585/661 processed\n",
      "2024-05-26 23:21:24,000 - INFO - Batch 586/661 processed\n",
      "2024-05-26 23:21:28,042 - INFO - Batch 587/661 processed\n",
      "2024-05-26 23:21:32,077 - INFO - Batch 588/661 processed\n",
      "2024-05-26 23:21:36,096 - INFO - Batch 589/661 processed\n",
      "2024-05-26 23:21:40,118 - INFO - Batch 590/661 processed\n",
      "2024-05-26 23:21:44,143 - INFO - Batch 591/661 processed\n",
      "2024-05-26 23:21:48,170 - INFO - Batch 592/661 processed\n",
      "2024-05-26 23:21:52,303 - INFO - Batch 593/661 processed\n",
      "2024-05-26 23:21:56,318 - INFO - Batch 594/661 processed\n",
      "2024-05-26 23:22:00,349 - INFO - Batch 595/661 processed\n",
      "2024-05-26 23:22:04,380 - INFO - Batch 596/661 processed\n",
      "2024-05-26 23:22:08,490 - INFO - Batch 597/661 processed\n",
      "2024-05-26 23:22:12,551 - INFO - Batch 598/661 processed\n",
      "2024-05-26 23:22:16,569 - INFO - Batch 599/661 processed\n",
      "2024-05-26 23:22:20,585 - INFO - Batch 600/661 processed\n",
      "2024-05-26 23:22:24,608 - INFO - Batch 601/661 processed\n",
      "2024-05-26 23:22:28,622 - INFO - Batch 602/661 processed\n",
      "2024-05-26 23:22:32,645 - INFO - Batch 603/661 processed\n",
      "2024-05-26 23:22:36,672 - INFO - Batch 604/661 processed\n",
      "2024-05-26 23:22:40,706 - INFO - Batch 605/661 processed\n",
      "2024-05-26 23:22:44,752 - INFO - Batch 606/661 processed\n",
      "2024-05-26 23:22:48,776 - INFO - Batch 607/661 processed\n",
      "2024-05-26 23:22:52,795 - INFO - Batch 608/661 processed\n",
      "2024-05-26 23:22:56,816 - INFO - Batch 609/661 processed\n",
      "2024-05-26 23:23:00,842 - INFO - Batch 610/661 processed\n",
      "2024-05-26 23:23:04,861 - INFO - Batch 611/661 processed\n",
      "2024-05-26 23:23:08,881 - INFO - Batch 612/661 processed\n",
      "2024-05-26 23:23:12,900 - INFO - Batch 613/661 processed\n",
      "2024-05-26 23:23:16,929 - INFO - Batch 614/661 processed\n",
      "2024-05-26 23:23:20,954 - INFO - Batch 615/661 processed\n",
      "2024-05-26 23:23:24,984 - INFO - Batch 616/661 processed\n",
      "2024-05-26 23:23:29,006 - INFO - Batch 617/661 processed\n",
      "2024-05-26 23:23:33,023 - INFO - Batch 618/661 processed\n",
      "2024-05-26 23:23:37,035 - INFO - Batch 619/661 processed\n",
      "2024-05-26 23:23:41,066 - INFO - Batch 620/661 processed\n",
      "2024-05-26 23:23:45,107 - INFO - Batch 621/661 processed\n",
      "2024-05-26 23:23:49,145 - INFO - Batch 622/661 processed\n",
      "2024-05-26 23:23:53,169 - INFO - Batch 623/661 processed\n",
      "2024-05-26 23:23:57,193 - INFO - Batch 624/661 processed\n",
      "2024-05-26 23:24:01,223 - INFO - Batch 625/661 processed\n",
      "2024-05-26 23:24:05,237 - INFO - Batch 626/661 processed\n",
      "2024-05-26 23:24:09,268 - INFO - Batch 627/661 processed\n",
      "2024-05-26 23:24:13,311 - INFO - Batch 628/661 processed\n",
      "2024-05-26 23:24:17,335 - INFO - Batch 629/661 processed\n",
      "2024-05-26 23:24:21,353 - INFO - Batch 630/661 processed\n",
      "2024-05-26 23:24:25,373 - INFO - Batch 631/661 processed\n",
      "2024-05-26 23:24:29,426 - INFO - Batch 632/661 processed\n",
      "2024-05-26 23:24:33,486 - INFO - Batch 633/661 processed\n",
      "2024-05-26 23:24:37,515 - INFO - Batch 634/661 processed\n",
      "2024-05-26 23:24:41,532 - INFO - Batch 635/661 processed\n",
      "2024-05-26 23:24:45,548 - INFO - Batch 636/661 processed\n",
      "2024-05-26 23:24:49,563 - INFO - Batch 637/661 processed\n",
      "2024-05-26 23:24:53,570 - INFO - Batch 638/661 processed\n",
      "2024-05-26 23:24:57,591 - INFO - Batch 639/661 processed\n",
      "2024-05-26 23:25:01,629 - INFO - Batch 640/661 processed\n",
      "2024-05-26 23:25:05,675 - INFO - Batch 641/661 processed\n",
      "2024-05-26 23:25:09,691 - INFO - Batch 642/661 processed\n",
      "2024-05-26 23:25:13,711 - INFO - Batch 643/661 processed\n",
      "2024-05-26 23:25:17,723 - INFO - Batch 644/661 processed\n",
      "2024-05-26 23:25:21,756 - INFO - Batch 645/661 processed\n",
      "2024-05-26 23:25:25,764 - INFO - Batch 646/661 processed\n",
      "2024-05-26 23:25:29,773 - INFO - Batch 647/661 processed\n",
      "2024-05-26 23:25:33,815 - INFO - Batch 648/661 processed\n",
      "2024-05-26 23:25:37,823 - INFO - Batch 649/661 processed\n",
      "2024-05-26 23:25:41,846 - INFO - Batch 650/661 processed\n",
      "2024-05-26 23:25:45,870 - INFO - Batch 651/661 processed\n",
      "2024-05-26 23:25:49,976 - INFO - Batch 652/661 processed\n",
      "2024-05-26 23:25:54,103 - INFO - Batch 653/661 processed\n",
      "2024-05-26 23:25:58,157 - INFO - Batch 654/661 processed\n",
      "2024-05-26 23:26:02,190 - INFO - Batch 655/661 processed\n",
      "2024-05-26 23:26:06,222 - INFO - Batch 656/661 processed\n",
      "2024-05-26 23:26:10,240 - INFO - Batch 657/661 processed\n",
      "2024-05-26 23:26:14,263 - INFO - Batch 658/661 processed\n",
      "2024-05-26 23:26:18,274 - INFO - Batch 659/661 processed\n",
      "2024-05-26 23:26:22,284 - INFO - Batch 660/661 processed\n",
      "2024-05-26 23:26:22,754 - INFO - Batch 661/661 processed\n",
      "2024-05-26 23:26:22,762 - INFO - Extracting features for test set\n",
      "2024-05-26 23:26:26,587 - INFO - Batch 1/2 processed\n",
      "2024-05-26 23:26:27,367 - INFO - Batch 2/2 processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a custom dataset class\n",
    "class BirdSoundDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, label_encoder):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.processor = processor\n",
    "        self.label_encoder = label_encoder\n",
    "        self.data[\"Encoded Labels\"] = self.label_encoder.transform(self.data[\"Common Name\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx][\"File Path\"]\n",
    "        label = self.data.iloc[idx][\"Encoded Labels\"]\n",
    "        \n",
    "        # Load and preprocess the audio file\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        \n",
    "        # Ensure the audio is mono\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Ensure the audio is exactly 10 seconds (or pad if shorter)\n",
    "        fixed_length = 10 * 16000  # 10 seconds * 16000 Hz\n",
    "        if waveform.size(1) > fixed_length:\n",
    "            waveform = waveform[:, :fixed_length]\n",
    "        else:\n",
    "            padding = fixed_length - waveform.size(1)\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "        \n",
    "        inputs = self.processor(waveform.squeeze(0), sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        return {\"input_values\": inputs.input_values.squeeze(0), \"labels\": torch.tensor(label)}\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"./dataset/train_final.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/test_final.csv\")\n",
    "\n",
    "# Combine the datasets to fit the LabelEncoder on all unique classes\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Initialize and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(combined_df[\"Common Name\"])\n",
    "\n",
    "# Instantiate the processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Load datasets directly using the fitted label encoder\n",
    "train_dataset = BirdSoundDataset(csv_file=\"./dataset/train_final.csv\", processor=processor, label_encoder=label_encoder)\n",
    "test_dataset = BirdSoundDataset(csv_file=\"./dataset/test_final.csv\", processor=processor, label_encoder=label_encoder)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load the pre-trained Wav2Vec2 model\n",
    "feature_extractor = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(data_loader, model):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            input_values = batch[\"input_values\"].to(device)\n",
    "            label = batch[\"labels\"]\n",
    "            \n",
    "            outputs = model(input_values).last_hidden_state\n",
    "            features.append(outputs.mean(dim=1).cpu().numpy())  # Average over time dimension\n",
    "            labels.append(label.numpy())\n",
    "            logger.info(f'Batch {i+1}/{len(data_loader)} processed')\n",
    "    \n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "# Extract features for train and test sets\n",
    "logger.info(\"Extracting features for training set\")\n",
    "train_features, train_labels = extract_features(train_loader, feature_extractor)\n",
    "logger.info(\"Extracting features for test set\")\n",
    "test_features, test_labels = extract_features(test_loader, feature_extractor)\n",
    "\n",
    "# Save extracted features and labels to npy files\n",
    "np.save(\"train_features.npy\", train_features)\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"test_features.npy\", test_features)\n",
    "np.save(\"test_labels.npy\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeb88a6f-04dc-4362-b01e-68c742356f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"dataset/train_final.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test_final.csv\")\n",
    "\n",
    "# Combine the datasets to calculate the frequency of each class\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Calculate the frequency of each class\n",
    "class_counts = combined_df[\"Common Name\"].value_counts()\n",
    "\n",
    "# Filter out classes with fewer than 3 instances\n",
    "filtered_classes = class_counts[class_counts >= 3].index\n",
    "\n",
    "# Filter the datasets\n",
    "filtered_train_df = train_df[train_df[\"Common Name\"].isin(filtered_classes)]\n",
    "filtered_test_df = test_df[test_df[\"Common Name\"].isin(filtered_classes)]\n",
    "\n",
    "# Ensure the index is reset\n",
    "filtered_train_df = filtered_train_df.reset_index(drop=True)\n",
    "filtered_test_df = filtered_test_df.reset_index(drop=True)\n",
    "\n",
    "# Load extracted features\n",
    "train_features = np.load(\"train_features.npy\")\n",
    "test_features = np.load(\"test_features.npy\")\n",
    "\n",
    "# Filter the features based on the filtered datasets\n",
    "filtered_train_features = train_features[filtered_train_df.index]\n",
    "filtered_test_features = test_features[filtered_test_df.index]\n",
    "\n",
    "# Save the filtered datasets and features (optional)\n",
    "filtered_train_df.to_csv(\"dataset/train_final_filtered.csv\", index=False)\n",
    "filtered_test_df.to_csv(\"dataset/test_final_filtered.csv\", index=False)\n",
    "np.save(\"train_features_filtered.npy\", filtered_train_features)\n",
    "np.save(\"test_features_filtered.npy\", filtered_test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e96c42f-5089-4974-b6b7-69100edbaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine the filtered datasets to fit the LabelEncoder on all unique classes\n",
    "filtered_combined_df = pd.concat([filtered_train_df, filtered_test_df])\n",
    "\n",
    "# Initialize and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(filtered_combined_df[\"Common Name\"])\n",
    "\n",
    "# Encode labels\n",
    "filtered_train_labels = label_encoder.transform(filtered_train_df[\"Common Name\"])\n",
    "filtered_test_labels = label_encoder.transform(filtered_test_df[\"Common Name\"])\n",
    "\n",
    "# Save encoded labels\n",
    "np.save(\"train_labels_filtered.npy\", filtered_train_labels)\n",
    "np.save(\"test_labels_filtered.npy\", filtered_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ccb13-db68-4086-b9a2-832ab1ef76f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 00:09:31,829 - INFO - Unique labels in train data: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582]\n",
      "2024-05-27 00:09:31,830 - INFO - Unique labels in test data: [ 43  47  56  84  89 135 449 493 530 561]\n",
      "2024-05-27 00:09:31,831 - INFO - Starting hyperparameter search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_features: 4751\n",
      "Length of train_labels: 4751\n",
      "Length of test_features: 10\n",
      "Length of test_labels: 10\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load extracted features and encoded labels\n",
    "train_features = np.load(\"train_features_filtered.npy\")\n",
    "test_features = np.load(\"test_features_filtered.npy\")\n",
    "train_labels = np.load(\"train_labels_filtered.npy\")\n",
    "test_labels = np.load(\"test_labels_filtered.npy\")\n",
    "\n",
    "# Check lengths\n",
    "print(f\"Length of train_features: {len(train_features)}\")\n",
    "print(f\"Length of train_labels: {len(train_labels)}\")\n",
    "print(f\"Length of test_features: {len(test_features)}\")\n",
    "print(f\"Length of test_labels: {len(test_labels)}\")\n",
    "\n",
    "# Check unique labels in train_labels and test_labels\n",
    "unique_train_labels = np.unique(train_labels)\n",
    "unique_test_labels = np.unique(test_labels)\n",
    "num_classes = len(unique_train_labels)\n",
    "\n",
    "logger.info(f\"Unique labels in train data: {unique_train_labels}\")\n",
    "logger.info(f\"Unique labels in test data: {unique_test_labels}\")\n",
    "\n",
    "# Instantiate the XGBoost classifier with GPU support\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax', \n",
    "    num_class=num_classes,  # Use the number of unique classes in the training labels\n",
    "    random_state=42, \n",
    "    tree_method='gpu_hist',  # Use GPU acceleration\n",
    "    predictor='gpu_predictor'\n",
    ")\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Instantiate the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Instantiate the GridSearchCV object with Stratified K-Folds\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=skf, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model\n",
    "logger.info(\"Starting hyperparameter search\")\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "logger.info(\"Evaluating the best model\")\n",
    "train_preds = best_xgb.predict(train_features)\n",
    "test_preds = best_xgb.predict(test_features)\n",
    "\n",
    "train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "logger.info(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "logger.info(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_xgb, 'best_xgboost_classifier.joblib')\n",
    "logger.info(\"Best model saved\")\n",
    "\n",
    "# Decode the predicted and true labels\n",
    "decoded_test_preds = label_encoder.inverse_transform(test_preds)\n",
    "decoded_test_labels = label_encoder.inverse_transform(test_labels)\n",
    "\n",
    "# Print the predicted and true labels\n",
    "for i in range(len(decoded_test_labels)):\n",
    "    logger.info(f\"True label: {decoded_test_labels[i]}, Predicted label: {decoded_test_preds[i]}\")\n",
    "\n",
    "# Optionally save the results to a CSV file\n",
    "results_df = pd.DataFrame({\n",
    "    \"File Path\": filtered_test_df[\"File Path\"],\n",
    "    \"True Label\": decoded_test_labels,\n",
    "    \"Predicted Label\": decoded_test_preds\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"test_results.csv\", index=False)\n",
    "logger.info(\"Results saved to test_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57313fbb-724f-4f69-ac35-6c3f75c7ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "logger.info(\"Evaluating the best model\")\n",
    "train_preds = best_xgb.predict(train_features)\n",
    "test_preds = best_xgb.predict(test_features)\n",
    "\n",
    "train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "logger.info(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "logger.info(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_xgb, 'best_xgboost_classifier.joblib')\n",
    "logger.info(\"Best model saved\")\n",
    "\n",
    "# Decode the predicted and true labels\n",
    "decoded_test_preds = label_encoder.inverse_transform(test_preds)\n",
    "decoded_test_labels = label_encoder.inverse_transform(test_labels)\n",
    "\n",
    "# Print the predicted and true labels\n",
    "for i in range(len(decoded_test_labels)):\n",
    "    logger.info(f\"True label: {decoded_test_labels[i]}, Predicted label: {decoded_test_preds[i]}\")\n",
    "\n",
    "# Optionally save the results to a CSV file\n",
    "results_df = pd.DataFrame({\n",
    "    \"File Path\": test_dataset.data[\"File Path\"],\n",
    "    \"True Label\": decoded_test_labels,\n",
    "    \"Predicted Label\": decoded_test_preds\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"test_results.csv\", index=False)\n",
    "logger.info(\"Results saved to test_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
