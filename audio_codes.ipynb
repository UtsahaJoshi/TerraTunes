{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208b2ad2-3e3e-4b18-acfa-ebba1a89d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_162702_0_00027_255.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_162702_0_00027_255_denoised.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_203102_0_00027_362.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_203202_0_00041_271.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_203302_0_00000_000.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_204202_0_00051_617.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_210702_0_00004_876.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_210702_0_00036_258.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_210802_0_00005_154.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_210902_0_00041_698.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_215602_0_00032_311.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_215602_0_00049_932.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_221802_0_00003_596.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_222102_0_00014_796.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_223702_0_00047_650.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_223902_0_00018_402.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_224202_0_00023_607.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_224802_0_00015_927.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_224902_0_00004_599.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_224902_0_00040_204.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_225002_0_00036_620.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_225302_0_00042_850.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_225802_0_00013_794.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_230802_0_00035_148.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_230802_0_00051_127.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_230902_0_00003_447.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_231102_0_00006_754.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_231202_0_00036_983.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_232202_0_00000_000.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_232402_0_00007_607.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_232402_0_00045_452.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_232502_0_00003_234.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_233902_0_00023_692.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_234702_0_00028_492.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_234702_0_00043_276.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240409_234802_0_00005_410.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_194702_0_00010_636.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_194802_0_00034_551.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_194802_0_00047_180.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_195402_0_00045_089.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_195902_0_00050_764.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_200002_0_00015_692.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_202102_0_00023_650.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_202202_0_00006_818.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_202302_0_00000_170.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_202302_0_00015_970.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_202402_0_00022_946.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_202902_0_00051_831.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_210902_0_00008_631.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_211602_0_00023_244.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_211702_0_00021_836.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_211902_0_00036_833.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_212202_0_00014_967.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_212202_0_00039_543.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_212302_0_00043_426.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_215902_0_00000_000.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_221802_0_00016_119.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_222402_0_00042_807.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_222502_0_00030_028.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_222602_0_00028_130.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_224402_0_00019_084.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_224402_0_00034_188.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM15XPRIZE_20240410_224502_0_00031_031.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_055002_0_00011_362.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_080302_0_00033_356.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_191902_0_00005_324.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_192902_0_00046_860.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_193902_0_00014_199.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_194202_0_00010_594.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_195402_0_00012_578.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_200102_0_00031_308.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_200902_0_00012_535.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_201802_0_00011_703.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_202002_0_00017_335.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_202802_0_00050_210.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_203002_0_00043_959.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_203102_0_00027_767.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_203302_0_00000_064.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_203302_0_00000_866.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_204102_0_00019_532.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_204202_0_00033_932.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_204702_0_00039_223.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_205002_0_00012_620.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_205002_0_00026_999.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_205102_0_00043_041.wav...\n",
      "Processing clusters225-2000Hz\\000\\SM4XPRIZE_20240409_205202_0_00041_420.wav...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m             file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subdir, file)\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m             audio_codes \u001b[38;5;241m=\u001b[39m encode_wav_file(file_path)\n\u001b[0;32m     44\u001b[0m             audio_codes_list\u001b[38;5;241m.\u001b[39mappend(audio_codes)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Convert the list of audio codes to a numpy array\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 29\u001b[0m, in \u001b[0;36mencode_wav_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     27\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(waveform, sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 29\u001b[0m     audio_codes \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m], inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpadding_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m24.0\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m audio_codes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:645\u001b[0m, in \u001b[0;36mEncodecModel.encode\u001b[1;34m(self, input_values, padding_mask, bandwidth, return_dict)\u001b[0m\n\u001b[0;32m    643\u001b[0m mask \u001b[38;5;241m=\u001b[39m padding_mask[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, offset : offset \u001b[38;5;241m+\u001b[39m chunk_length]\u001b[38;5;241m.\u001b[39mbool()\n\u001b[0;32m    644\u001b[0m frame \u001b[38;5;241m=\u001b[39m input_values[:, :, offset : offset \u001b[38;5;241m+\u001b[39m chunk_length]\n\u001b[1;32m--> 645\u001b[0m encoded_frame, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_frame(frame, bandwidth, mask)\n\u001b[0;32m    646\u001b[0m encoded_frames\u001b[38;5;241m.\u001b[39mappend(encoded_frame)\n\u001b[0;32m    647\u001b[0m scales\u001b[38;5;241m.\u001b[39mappend(scale)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:578\u001b[0m, in \u001b[0;36mEncodecModel._encode_frame\u001b[1;34m(self, input_values, bandwidth, padding_mask)\u001b[0m\n\u001b[0;32m    575\u001b[0m     scale \u001b[38;5;241m=\u001b[39m mono\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m\n\u001b[0;32m    576\u001b[0m     input_values \u001b[38;5;241m=\u001b[39m input_values \u001b[38;5;241m/\u001b[39m scale\n\u001b[1;32m--> 578\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(input_values)\n\u001b[0;32m    579\u001b[0m codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantizer\u001b[38;5;241m.\u001b[39mencode(embeddings, bandwidth)\n\u001b[0;32m    580\u001b[0m codes \u001b[38;5;241m=\u001b[39m codes\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:306\u001b[0m, in \u001b[0;36mEncodecEncoder.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 306\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m layer(hidden_states)\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:274\u001b[0m, in \u001b[0;36mEncodecResnetBlock.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    272\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock:\n\u001b[1;32m--> 274\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer(hidden_states)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(residual) \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:157\u001b[0m, in \u001b[0;36mEncodecConv1d.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m--> 157\u001b[0m     extra_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_padding_for_conv1d(hidden_states)\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcausal:\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;66;03m# Left padding for causal\u001b[39;00m\n\u001b[0;32m    161\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pad1d(hidden_states, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_total, extra_padding), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:133\u001b[0m, in \u001b[0;36mEncodecConv1d._get_extra_padding_for_conv1d\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    131\u001b[0m n_frames \u001b[38;5;241m=\u001b[39m (length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_total) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    132\u001b[0m n_frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mceil(n_frames)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 133\u001b[0m ideal_length \u001b[38;5;241m=\u001b[39m n_frames \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_total\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ideal_length \u001b[38;5;241m-\u001b[39m length\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_backward_pre_hooks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m-> 1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1603\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import AutoProcessor, EncodecModel\n",
    "\n",
    "# Load the Encodec model and processor\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")\n",
    "model = EncodecModel.from_pretrained(\"facebook/encodec_24khz\")\n",
    "\n",
    "# Function to process and encode a single WAV file\n",
    "def encode_wav_file(file_path):\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "    # Resample to 24kHz if necessary\n",
    "    if sample_rate != 24000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=24000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    waveform = waveform.squeeze().numpy()\n",
    "\n",
    "    # Ensure that the audio has a single channel\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform[0]\n",
    "    # Encode the waveform\n",
    "    inputs = processor(waveform, sampling_rate=24000, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        audio_codes = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"], 24.0)\n",
    "    return audio_codes[0].squeeze().cpu().numpy()\n",
    "\n",
    "# Directory containing the soundscape folder\n",
    "root_dir = \"clusters225-2000Hz\"\n",
    "\n",
    "# Collect all WAV files and their encoded audio codes\n",
    "audio_codes_list = []\n",
    "\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            print(f\"Processing {file_path}...\")\n",
    "            audio_codes = encode_wav_file(file_path)\n",
    "            audio_codes_list.append(audio_codes)\n",
    "\n",
    "# Convert the list of audio codes to a numpy array\n",
    "audio_codes_array = np.array(audio_codes_list, dtype=object)\n",
    "\n",
    "# Save the numpy array to an NPY file\n",
    "np.save(\"audio_codes.npy\", audio_codes_array)\n",
    "\n",
    "print(\"All audio codes have been saved to audio_codes.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ac873-6f48-461e-b807-a24364f0d2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
